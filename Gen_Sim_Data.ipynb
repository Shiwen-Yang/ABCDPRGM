{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as tm\n",
    "from src import Simulation as sim\n",
    "from src import Align\n",
    "from src import ABC_Reg\n",
    "from src import Dir_Reg as DR\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else device\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data sets that illustrate how the parameters of the model influence the behavior of the model. \n",
    "<br>\n",
    "Settings:\n",
    "<br>\n",
    "Length of Time: 20 or 200\n",
    "<br>\n",
    "Embedding Dimemsion: 2\n",
    "<br>\n",
    "Number of Nodes: 1200\n",
    "<br>\n",
    "Parameters:  (1, 1, 2, 5), (1, 1, 1, 5), (1, 1, -2, 5), (1, 1, -4, 5)\n",
    "<br>\n",
    "Initial Distribution: Dir(1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(4)\n",
    "\n",
    "T, n, alpha_0 = 20, 1200, [[1,1,1], [1,1,1], [1,1,1]]\n",
    "\n",
    "model_pos_2 = sim.ABC(time = T,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, 2, 5],\n",
    "                    alpha_0 = alpha_0)\n",
    "model_pos_1 = sim.ABC(time = T*10,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, 1 , 5],\n",
    "                    alpha_0 = alpha_0)\n",
    "model_neg_2 = sim.ABC(time = T*10,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, -2, 5],\n",
    "                    alpha_0 = alpha_0)\n",
    "model_neg_4 = sim.ABC(time = T,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, -4, 5],\n",
    "                    alpha_0 = alpha_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.ABC_Monte_Carlo.lat_pos(model_pos_2.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/pos_2_sample.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(model_pos_1.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/pos_1_sample.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(model_neg_2.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/neg_2_sample.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(model_neg_4.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/neg_4_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data sets that illustrate \n",
    "1. what the latent position recovered from ASE alone look like, what it looks like after oracle and RGD alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, T, beta, alpha_0 = 2, 2, [1, 1, -4, 5], [[10,1,1], [1,10,1], [1,1,10]]\n",
    "model = sim.ABC(time = T, nodes = 3, beta = beta, alpha_0 = alpha_0)\n",
    "torch.manual_seed(0)\n",
    "lat_pos = sim.ABC_Monte_Carlo.check_lat_pos(model, 4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.truth, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/tru_lat_pos.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.ASE, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/ASE_lat_pos.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.ASE_aligned, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/ASE_aligned_lat_pos.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.RGD_aligned, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/RGD_aligned_lat_pos.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. how the latent position recovered from an oracle-given orthogonal transformation converges to the true latent position in $\\|*\\|_{2 \\to \\infty}$. \n",
    "3. how the latent position recovered from RGD performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_2_infty(X):\n",
    "    result = torch.max(torch.sqrt(((X)**2).sum(dim = 2)), dim = 1).values\n",
    "    return(result)\n",
    "\n",
    "def mat_sqrt(X, dim):\n",
    "    X_LR_svd = torch.svd_lowrank(X, dim)\n",
    "    u = X_LR_svd[0]\n",
    "    v = torch.diag(X_LR_svd[1])\n",
    "    result = u @ torch.sqrt(v)\n",
    "    return(result)\n",
    "\n",
    "def performance(dist, n_set, N_iter):\n",
    "    core = torch.cat(dist).reshape(len(n_set), N_iter, 2).mean(dim = 1)\n",
    "    nodes = n_set.unsqueeze(dim = 1)\n",
    "    iter = torch.ones(len(n_set), 1) * N_iter\n",
    "    full = torch.cat([iter, nodes, core], dim = 1)\n",
    "    result = pd.DataFrame(full, columns = [\"iter\", \"nodes\", \"error_T0\", \"error_T1\"])\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, T, beta, alpha_0 = 2, 2, [1, 1, -4, 5], [[10,1,1], [1,10,1], [1,1,10]]\n",
    "model = sim.ABC(time = T, nodes = 3, beta = beta, alpha_0 = alpha_0)\n",
    "torch.manual_seed(0)\n",
    "lat_pos = sim.ABC_Monte_Carlo.check_lat_pos(model, 4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(1500): 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n",
      "tensor(2250): 100%|██████████| 1/1 [00:00<00:00,  3.62it/s]\n",
      "tensor(3000): 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "tensor(3750): 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "tensor(4500): 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "tensor(5250): 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "tensor(6000): 100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "tensor(6750): 100%|██████████| 1/1 [00:06<00:00,  6.42s/it]\n",
      "tensor(7500): 100%|██████████| 1/1 [00:10<00:00, 10.81s/it]\n",
      "tensor(8250): 100%|██████████| 1/1 [00:12<00:00, 12.59s/it]\n",
      "tensor(9000): 100%|██████████| 1/1 [00:14<00:00, 14.25s/it]\n",
      "tensor(9750): 100%|██████████| 1/1 [00:11<00:00, 11.34s/it]\n",
      "tensor(10500): 100%|██████████| 1/1 [00:17<00:00, 17.60s/it]\n",
      "tensor(11250): 100%|██████████| 1/1 [00:14<00:00, 14.83s/it]\n",
      "tensor(12000): 100%|██████████| 1/1 [00:21<00:00, 21.71s/it]\n"
     ]
    }
   ],
   "source": [
    "n_set = torch.arange(1500, 12001, 750)\n",
    "N_iter = 1\n",
    "ortho_trans = torch.tensor([[0,1.], [1, 0]])\n",
    "\n",
    "ASE_dist = []\n",
    "RGD_dist = []\n",
    "for n in n_set:\n",
    "    for i in tm(range(N_iter), desc = str(n)):\n",
    "        torch.manual_seed(i)\n",
    "        lat_pos = sim.ABC_Monte_Carlo.check_lat_pos(model, n)\n",
    "        ASE_two_infty = norm_2_infty(lat_pos.truth - lat_pos.ASE_aligned)\n",
    "        ASE_dist.append(ASE_two_infty)\n",
    "\n",
    "        if torch.diag(Align.Oracle.ortho_proc(lat_pos.ASE_aligned[0,], lat_pos.RGD_aligned[0,])).sum() < 0.1:\n",
    "            lat_pos.RGD_aligned[0,] = lat_pos.RGD_aligned[0,] @ ortho_trans\n",
    "            lat_pos.RGD_aligned[1,] = lat_pos.RGD_aligned[1,] @ ortho_trans\n",
    "        RGD_two_infty = norm_2_infty(lat_pos.truth - lat_pos.RGD_aligned)\n",
    "        RGD_dist.append(RGD_two_infty)\n",
    "\n",
    "Oracle_performace = performance(ASE_dist, n_set, N_iter)\n",
    "RGD_performance = performance(RGD_dist, n_set, N_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Oracle_performace.to_csv(r\"simulated_data/est_lat_pos/example_1/convergence/oracle_performance.csv\")\n",
    "RGD_performance.to_csv(r\"simulated_data/est_lat_pos/example_1/convergence/RGD_performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below we generate the synthetic data set that shows how the latent position in ABCDPRGM evolves through time under different settings (different levels of knowledge about the latent positions).**\n",
    "\n",
    "**Let $\\widehat{B} \\in \\mathbb{R}^{q \\times p}$ be the MLE that corresponds to the design matrix $X \\otimes I_p$, and $\\tilde{\\beta} = (C^T C)^{-1} C^T \\widehat{B}$. Let $\\widehat{\\beta}$ be the MLE that corresponds to the design matrix $(X \\otimes I_p)C$.**\n",
    "\n",
    "**We do Monte Carlo simulations to verify the asymptotic behavior of $\\widehat{B}$ and $\\tilde{\\beta}$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first verify that with the initial latent positions that we are using, there isn't a significant different between initializing at the true parameter vs. initializing using a parameter estimated by linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(1500): 100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "tensor(2250): 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "tensor(3000): 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "tensor(1500): 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "tensor(2250): 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "tensor(3000): 100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "n_set = torch.arange(1500, 3001, 750)\n",
    "beta = [1,1,-4, 5]\n",
    "alpha_0 = [[10, 1, 1], [1, 10, 1], [1, 1, 10]]\n",
    "OL, OA, NO = True, True, True\n",
    "ntypes = OL + OA + NO\n",
    "\n",
    "oracle_guess_results = sim.ABC_Monte_Carlo.consistency_T2(number_of_iterations = N, \n",
    "                                          nodes_set = n_set,\n",
    "                                          beta = beta,\n",
    "                                          alpha_0 = alpha_0,\n",
    "                                          oracle_guess = True,\n",
    "                                          seeded = True,\n",
    "                                          constrained = False,\n",
    "                                          oracle_lat_pos = OL,\n",
    "                                          oracle_align = OA,\n",
    "                                          no_oracle = NO)\n",
    "shiwen_guess_results = sim.ABC_Monte_Carlo.consistency_T2(number_of_iterations = N, \n",
    "                                          nodes_set = n_set,\n",
    "                                          beta = beta,\n",
    "                                          alpha_0 = alpha_0,\n",
    "                                          oracle_guess = False,\n",
    "                                          seeded = True,\n",
    "                                          constrained = False,\n",
    "                                          oracle_lat_pos = OL,\n",
    "                                          oracle_align = OA,\n",
    "                                          no_oracle = NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_guess_results.MC_result.est.to_csv(r\"simulated_data\\theo_var_vs_emp_var\\justify_oracle_guess\\oracle_init_est.csv\")\n",
    "shiwen_guess_results.MC_result.est.to_csv(r\"simulated_data\\theo_var_vs_emp_var\\justify_oracle_guess\\lin_reg_init_est.csv\")\n",
    "\n",
    "oracle_guess_results.MC_result.fish.to_csv(r\"simulated_data\\theo_var_vs_emp_var\\justify_oracle_guess\\oracle_init_fish.csv\")\n",
    "shiwen_guess_results.MC_result.fish.to_csv(r\"simulated_data\\theo_var_vs_emp_var\\justify_oracle_guess\\lin_reg_init_fish.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there isn't any significant difference between initializing at the true parameter vs. initializing with linear regression, we will initialize at the true parameter in the following monte-carlo experiment to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "n_set = torch.arange(1500, 12001, 750)\n",
    "beta = [1,1,-4, 5]\n",
    "alpha_0 = [[10, 1, 1], [1, 10, 1], [1, 1, 10]]\n",
    "OL, OA, NO = True, True, True\n",
    "ntypes = OL + OA + NO\n",
    "\n",
    "oracle_guess_results = sim.ABC_Monte_Carlo.consistency_T2(number_of_iterations = N, \n",
    "                                          nodes_set = n_set,\n",
    "                                          beta = beta,\n",
    "                                          alpha_0 = alpha_0,\n",
    "                                          oracle_guess = True,\n",
    "                                          seeded = True,\n",
    "                                          constrained = False,\n",
    "                                          oracle_lat_pos = OL,\n",
    "                                          oracle_align = OA,\n",
    "                                          no_oracle = NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_guess_results.MC_result.est.to_csv(r\"simulated_data/theo_var_vs_emp_var/consistency/est_all.csv\")\n",
    "oracle_guess_results.MC_result.fish.to_csv(r\"simulated_data/theo_var_vs_emp_var/consistency/fish_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to investigate what happens to our estimation, when we use the correct model, but misspecify the dimension.\n",
    "\n",
    "We first embed the graph in lower dimension, run regression, and then compare result to the truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, K, T = 6, 6, 2\n",
    "# alpha_0 = torch.ones(K, p)*2\n",
    "alpha_0 = torch.eye(p)*9 + 1\n",
    "# alpha_0 = torch.kron(torch.eye(int(p/2))*9 + 1, torch.ones(2))\n",
    "\n",
    "model = sim.ABC(time = T,\n",
    "        nodes = 30,\n",
    "        beta = [1, 1, -4, 5],\n",
    "        alpha_0 = alpha_0)\n",
    "\n",
    "seed_list = list(range(50))\n",
    "n_list = list(range(1500, 6001, 1500))\n",
    "p0_list = list(range(2, 7))\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results = []\n",
    "for seed in seed_list:\n",
    "    torch.manual_seed(seed)\n",
    "    for n in n_list:\n",
    "        for p0 in p0_list:\n",
    "            # Update model settings\n",
    "            model.update_settings(nodes = n)\n",
    "            # Initialize estimation\n",
    "            estimate = ABC_Reg.est(two_lat_pos = model.synth_data['lat_pos'],\n",
    "                    two_adj_mat = model.synth_data['obs_adj'],\n",
    "                    groups = K,\n",
    "                    )\n",
    "            # Perform estimation by specifying mode and embedding dimension p0\n",
    "            estimate.specify_mode('NO', fit = True, embed_dim = p0)\n",
    "            \n",
    "            # Compute beta_est and info_lost\n",
    "            beta_est = DR.fit.proj_beta(estimate.fitted.est_result[\"estimate\"], DR.fit.gen_constraint(p0+1, True)).tolist()\n",
    "            info_lost = estimate.fitted.est_result[\"info_lost\"]\n",
    "            \n",
    "            # Create a dictionary for the current iteration\n",
    "            result = {\n",
    "                'seed': seed,\n",
    "                'n': n,\n",
    "                'p0': p0,\n",
    "                'beta1': beta_est[0],\n",
    "                'beta2': beta_est[1],\n",
    "                'beta3': beta_est[2],\n",
    "                'beta4': beta_est[3],\n",
    "                'info_lost': info_lost  # Optional: Include if you want to store this value\n",
    "            }\n",
    "            # Append the result to the list\n",
    "            results.append(result)\n",
    "\n",
    "# Convert the list of dictionaries to a pandas DataFrame\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"simulated_data\\dimension_robustness\\robustness.csv\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
