{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.distributions import Dirichlet, Bernoulli, Uniform\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as tm\n",
    "\n",
    "from src import Simulation as sim\n",
    "from src import Dir_Reg\n",
    "from src import Align\n",
    "from src import visualize_latent_space as vls\n",
    "from src import ABC_Reg\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else device\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data sets that illustrate how the parameters of the model influence the behavior of the model. \n",
    "<br>\n",
    "Settings:\n",
    "<br>\n",
    "Length of Time: 20 or 200\n",
    "<br>\n",
    "Embedding Dimemsion: 2\n",
    "<br>\n",
    "Number of Nodes: 1200\n",
    "<br>\n",
    "Parameters:  (1, 1, 5, 5), (1, 1, 2, 5), (1, 1, -2, 5), (1, 1, -5, 5)\n",
    "<br>\n",
    "Initial Distribution: Dir(1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(4)\n",
    "\n",
    "T, n, alpha_0 = 20, 300, [[1,1,1], [1,1,1], [1,1,1]]\n",
    "\n",
    "model_pos_2 = sim.ABC(time = T,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, 2, 5],\n",
    "                    alpha_0 = alpha_0)\n",
    "model_pos_1 = sim.ABC(time = T*10,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, 1 , 5],\n",
    "                    alpha_0 = alpha_0)\n",
    "model_neg_2 = sim.ABC(time = T*10,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, -2, 5],\n",
    "                    alpha_0 = alpha_0)\n",
    "model_neg_4 = sim.ABC(time = T,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, -4, 5],\n",
    "                    alpha_0 = alpha_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.ABC_Monte_Carlo.lat_pos(model_pos_2.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/pos_2_sample.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(model_pos_1.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/pos_1_sample.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(model_neg_2.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/neg_2_sample.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(model_neg_4.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/neg_4_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data sets that illustrate \n",
    "1. what the latent position recovered from ASE alone look like, what it looks like after oracle and RGD alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, T, beta, alpha_0 = 2, 2, [1, 1, -4, 5], [[10,1,1], [1,10,1], [1,1,10]]\n",
    "model = sim.ABC(time = T, nodes = 3, beta = beta, alpha_0 = alpha_0)\n",
    "torch.manual_seed(0)\n",
    "lat_pos = sim.ABC_Monte_Carlo.check_lat_pos(model, 4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.truth, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/tru_lat_pos.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.ASE, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/ASE_lat_pos.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.ASE_aligned, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/ASE_aligned_lat_pos.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.RGD_aligned, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/RGD_aligned_lat_pos.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. how the latent position recovered from an oracle-given orthogonal transformation converges to the true latent position in $\\|*\\|_{2 \\to \\infty}$. \n",
    "3. how the latent position recovered from RGD performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_2_infty(X):\n",
    "    result = torch.max(torch.sqrt(((X)**2).sum(dim = 2)), dim = 1).values\n",
    "    return(result)\n",
    "\n",
    "def mat_sqrt(X, dim):\n",
    "    X_LR_svd = torch.svd_lowrank(X, dim)\n",
    "    u = X_LR_svd[0]\n",
    "    v = torch.diag(X_LR_svd[1])\n",
    "    result = u @ torch.sqrt(v)\n",
    "    return(result)\n",
    "\n",
    "def performance(dist, n_set, N_iter):\n",
    "    core = torch.cat(dist).reshape(len(n_set), N_iter, 2).mean(dim = 1)\n",
    "    nodes = n_set.unsqueeze(dim = 1)\n",
    "    iter = torch.ones(len(n_set), 1) * N_iter\n",
    "    full = torch.cat([iter, nodes, core], dim = 1)\n",
    "    result = pd.DataFrame(full, columns = [\"iter\", \"nodes\", \"error_T0\", \"error_T1\"])\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, T, beta, alpha_0 = 2, 2, [1, 1, -4, 5], [[10,1,1], [1,10,1], [1,1,10]]\n",
    "model = sim.ABC(time = T, nodes = 3, beta = beta, alpha_0 = alpha_0)\n",
    "torch.manual_seed(0)\n",
    "lat_pos = sim.ABC_Monte_Carlo.check_lat_pos(model, 4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(1500): 100%|██████████| 10/10 [00:01<00:00,  7.30it/s]\n",
      "tensor(2250): 100%|██████████| 10/10 [00:02<00:00,  4.43it/s]\n",
      "tensor(3000): 100%|██████████| 10/10 [00:04<00:00,  2.49it/s]\n",
      "tensor(3750): 100%|██████████| 10/10 [00:06<00:00,  1.62it/s]\n",
      "tensor(4500): 100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n",
      "tensor(5250): 100%|██████████| 10/10 [00:13<00:00,  1.33s/it]\n",
      "tensor(6000): 100%|██████████| 10/10 [00:21<00:00,  2.19s/it]\n",
      "tensor(6750): 100%|██████████| 10/10 [00:35<00:00,  3.56s/it]\n",
      "tensor(7500): 100%|██████████| 10/10 [01:21<00:00,  8.17s/it]\n",
      "tensor(8250): 100%|██████████| 10/10 [01:18<00:00,  7.82s/it]\n",
      "tensor(9000): 100%|██████████| 10/10 [01:35<00:00,  9.56s/it]\n",
      "tensor(9750): 100%|██████████| 10/10 [01:53<00:00, 11.37s/it]\n",
      "tensor(10500): 100%|██████████| 10/10 [01:54<00:00, 11.49s/it]\n",
      "tensor(11250): 100%|██████████| 10/10 [02:14<00:00, 13.43s/it]\n",
      "tensor(12000): 100%|██████████| 10/10 [02:18<00:00, 13.85s/it]\n"
     ]
    }
   ],
   "source": [
    "n_set = torch.arange(1500, 12001, 750)\n",
    "N_iter = 10\n",
    "ortho_trans = torch.tensor([[0,1.], [1, 0]])\n",
    "\n",
    "ASE_dist = []\n",
    "RGD_dist = []\n",
    "for n in n_set:\n",
    "    for i in tm(range(N_iter), desc = str(n)):\n",
    "        torch.manual_seed(i)\n",
    "        lat_pos = sim.ABC_Monte_Carlo.check_lat_pos(model, n)\n",
    "        ASE_two_infty = norm_2_infty(lat_pos.truth - lat_pos.ASE_aligned)\n",
    "        ASE_dist.append(ASE_two_infty)\n",
    "\n",
    "        if torch.diag(Align.Oracle.ortho_proc(lat_pos.ASE_aligned[0,], lat_pos.RGD_aligned[0,])).sum() < 0.1:\n",
    "            lat_pos.RGD_aligned[0,] = lat_pos.RGD_aligned[0,] @ ortho_trans\n",
    "            lat_pos.RGD_aligned[1,] = lat_pos.RGD_aligned[1,] @ ortho_trans\n",
    "        RGD_two_infty = norm_2_infty(lat_pos.truth - lat_pos.RGD_aligned)\n",
    "        RGD_dist.append(RGD_two_infty)\n",
    "\n",
    "Oracle_performace = performance(ASE_dist, n_set, N_iter)\n",
    "RGD_performance = performance(RGD_dist, n_set, N_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Oracle_performace.to_csv(r\"simulated_data/est_lat_pos/example_1/convergence/oracle_performance.csv\")\n",
    "RGD_performance.to_csv(r\"simulated_data/est_lat_pos/example_1/convergence/RGD_performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we generate the synthetic data set that shows how the latent position in ABCDPRGM evolves through time under different settings.\n",
    "\n",
    "Let $\\widehat{B} \\in \\mathbb{R}^{q \\times p}$ be the MLE that corresponds to the design matrix $X \\otimes I_p$, and $\\tilde{\\beta} = (C^T C)^{-1} C^T \\widehat{B}$. Let $\\widehat{\\beta}$ be the MLE that corresponds to the design matrix $(X \\otimes I_p)C$.\n",
    "\n",
    "We first do Monte Carlo simulations to verify the asymptotic behavior of $\\widehat{B}$ and $\\tilde{\\beta}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(1500):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(1500): 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "tensor(2250): 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "tensor(3000): 100%|██████████| 1/1 [00:04<00:00,  4.41s/it]\n",
      "tensor(1500): 100%|██████████| 1/1 [00:03<00:00,  3.48s/it]\n",
      "tensor(2250): 100%|██████████| 1/1 [00:09<00:00,  9.97s/it]\n",
      "tensor(3000): 100%|██████████| 1/1 [00:17<00:00, 17.93s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" no_oracle option is for the RGD stuff, which is still somewhat problematic. It shouldn't be turned on. \"\"\"\n",
    "N = 1\n",
    "n_set = torch.arange(1500, 3001, 750)\n",
    "beta = [1,1,-4, 5]\n",
    "alpha_0 = [[10, 1, 1], [1, 10, 1], [1, 1, 10]]\n",
    "OL, OA, NO = True, True, True\n",
    "ntypes = OL + OA + NO\n",
    "\n",
    "oracle_guess_results = sim.ABC_Monte_Carlo.consistency_T2(number_of_iterations = N, \n",
    "                                          nodes_set = n_set,\n",
    "                                          beta = beta,\n",
    "                                          alpha_0 = alpha_0,\n",
    "                                          oracle_guess = True,\n",
    "                                          seeded = True,\n",
    "                                          constrained = False,\n",
    "                                          oracle_lat_pos = OL,\n",
    "                                          oracle_align = OA,\n",
    "                                          no_oracle = NO)\n",
    "shiwen_guess_results = sim.ABC_Monte_Carlo.consistency_T2(number_of_iterations = N, \n",
    "                                          nodes_set = n_set,\n",
    "                                          beta = beta,\n",
    "                                          alpha_0 = alpha_0,\n",
    "                                          oracle_guess = False,\n",
    "                                          seeded = True,\n",
    "                                          constrained = False,\n",
    "                                          oracle_lat_pos = OL,\n",
    "                                          oracle_align = OA,\n",
    "                                          no_oracle = NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "n_set = torch.arange(1500, 12001, 750)\n",
    "beta = [1,1,-4, 5]\n",
    "alpha_0 = [[10, 1, 1], [1, 10, 1], [1, 1, 10]]\n",
    "OL, OA, NO = True, True, True\n",
    "ntypes = OL + OA + NO\n",
    "\n",
    "oracle_guess_results = sim.ABC_Monte_Carlo.consistency_T2(number_of_iterations = N, \n",
    "                                          nodes_set = n_set,\n",
    "                                          beta = beta,\n",
    "                                          alpha_0 = alpha_0,\n",
    "                                          oracle_guess = True,\n",
    "                                          seeded = True,\n",
    "                                          constrained = False,\n",
    "                                          oracle_lat_pos = OL,\n",
    "                                          oracle_align = OA,\n",
    "                                          no_oracle = NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_guess_results.MC_result.est.to_csv(r\"simulated_data/theo_var_vs_emp_var/consistency/est_all.csv\")\n",
    "oracle_guess_results.MC_result.fish.to_csv(r\"simulated_data/theo_var_vs_emp_var/consistency/fish_all.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
