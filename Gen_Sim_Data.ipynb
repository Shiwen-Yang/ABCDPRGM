{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.distributions import Dirichlet, Bernoulli, Uniform\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as tm\n",
    "\n",
    "from src import Simulation as sim\n",
    "from src import Dir_Reg\n",
    "from src import Align\n",
    "from src import visualize_latent_space as vls\n",
    "from src import ABC_Reg\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else device\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data sets that illustrate how the parameters of the model influence the behavior of the model. \n",
    "<br>\n",
    "Settings:\n",
    "<br>\n",
    "Length of Time: 20 or 200\n",
    "<br>\n",
    "Embedding Dimemsion: 2\n",
    "<br>\n",
    "Number of Nodes: 1200\n",
    "<br>\n",
    "Parameters:  (1, 1, 5, 5), (1, 1, 2, 5), (1, 1, -2, 5), (1, 1, -5, 5)\n",
    "<br>\n",
    "Initial Distribution: Dir(1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(4)\n",
    "\n",
    "T, n, alpha_0 = 20, 300, [[1,1,1], [1,1,1], [1,1,1]]\n",
    "\n",
    "model_pos_2 = sim.ABC(time = T,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, 2, 5],\n",
    "                    alpha_0 = alpha_0)\n",
    "model_pos_1 = sim.ABC(time = T*10,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, 1 , 5],\n",
    "                    alpha_0 = alpha_0)\n",
    "model_neg_2 = sim.ABC(time = T*10,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, -2, 5],\n",
    "                    alpha_0 = alpha_0)\n",
    "model_neg_4 = sim.ABC(time = T,\n",
    "                    nodes = n,\n",
    "                    beta = [1, 1, -4, 5],\n",
    "                    alpha_0 = alpha_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.ABC_Monte_Carlo.lat_pos(model_pos_2.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/pos_2_sample.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(model_pos_1.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/pos_1_sample.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(model_neg_2.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/neg_2_sample.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(model_neg_4.synth_data[\"lat_pos\"], 3).to_csv(r\"simulated_data/time_vs_lat_pos/neg_4_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data sets that illustrate \n",
    "1. what the latent position recovered from ASE alone look like, what it looks like after oracle and RGD alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, T, beta, alpha_0 = 2, 2, [1, 1, -4, 5], [[10,1,1], [1,10,1], [1,1,10]]\n",
    "model = sim.ABC(time = T, nodes = 3, beta = beta, alpha_0 = alpha_0)\n",
    "torch.manual_seed(0)\n",
    "lat_pos = sim.ABC_Monte_Carlo.check_lat_pos(model, 4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.truth, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/tru_lat_pos.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.ASE, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/ASE_lat_pos.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.ASE_aligned, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/ASE_aligned_lat_pos.csv\")\n",
    "sim.ABC_Monte_Carlo.lat_pos(lat_pos.RGD_aligned, 3).to_csv(r\"simulated_data/est_lat_pos/example_1/estimate_lat_pos/RGD_aligned_lat_pos.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. how the latent position recovered from an oracle-given orthogonal transformation converges to the true latent position in $\\|*\\|_{2 \\to \\infty}$. \n",
    "3. how the latent position recovered from RGD performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_2_infty(X):\n",
    "    result = torch.max(torch.sqrt(((X)**2).sum(dim = 2)), dim = 1).values\n",
    "    return(result)\n",
    "\n",
    "def mat_sqrt(X, dim):\n",
    "    X_LR_svd = torch.svd_lowrank(X, dim)\n",
    "    u = X_LR_svd[0]\n",
    "    v = torch.diag(X_LR_svd[1])\n",
    "    result = u @ torch.sqrt(v)\n",
    "    return(result)\n",
    "\n",
    "def performance(dist, n_set, N_iter):\n",
    "    core = torch.cat(dist).reshape(len(n_set), N_iter, 2).mean(dim = 1)\n",
    "    nodes = n_set.unsqueeze(dim = 1)\n",
    "    iter = torch.ones(len(n_set), 1) * N_iter\n",
    "    full = torch.cat([iter, nodes, core], dim = 1)\n",
    "    result = pd.DataFrame(full, columns = [\"iter\", \"nodes\", \"error_T0\", \"error_T1\"])\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_set = torch.arange(1500, 12001, 750)\n",
    "N_iter = 100\n",
    "ortho_trans = torch.tensor([[0,1.], [1, 0]])\n",
    "\n",
    "ASE_dist = []\n",
    "RGD_dist = []\n",
    "for n in n_set:\n",
    "    for i in tm(range(N_iter), desc = str(n)):\n",
    "        torch.manual_seed(i)\n",
    "        lat_pos = sim.ABC_Monte_Carlo.check_lat_pos(model, n)\n",
    "        ASE_two_infty = norm_2_infty(lat_pos.truth - lat_pos.ASE_aligned)\n",
    "        ASE_dist.append(ASE_two_infty)\n",
    "\n",
    "        results = []\n",
    "        for i in range(2): \n",
    "            lpt = lat_pos.truth[i,]\n",
    "            lpra = lat_pos.RGD_aligned[i,]\n",
    "\n",
    "            rgd_dist = lpt @ lpt.T - lpra @ lpra.T\n",
    "            rgd_dist_sqrt = mat_sqrt(rgd_dist, 4).unsqueeze(dim=0)\n",
    "\n",
    "            results.append(rgd_dist_sqrt)\n",
    "\n",
    "        rgd_dist_sqrt_combined = torch.cat(results, dim=0)\n",
    "        RGD_two_infty = norm_2_infty(rgd_dist_sqrt_combined)\n",
    "\n",
    "        RGD_dist.append(RGD_two_infty)\n",
    "\n",
    "Oracle_performace = performance(ASE_dist, n_set, N_iter)\n",
    "RGD_performance = performance(RGD_dist, n_set, N_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Oracle_performace.to_csv(r\"simulated_data/est_lat_pos/example_1/convergence/oracle_performance.csv\")\n",
    "RGD_performance.to_csv(r\"simulated_data/est_lat_pos/example_1/convergence/RGD_performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we generate the synthetic data set that shows how the latent position in ABCDPRGM evolves through time under different settings.\n",
    "\n",
    "Let $\\widehat{B} \\in \\mathbb{R}^{q \\times p}$ be the MLE that corresponds to the design matrix $X \\otimes I_p$, and $\\tilde{\\beta} = (C^T C)^{-1} C^T \\widehat{B}$. Let $\\widehat{\\beta}$ be the MLE that corresponds to the design matrix $(X \\otimes I_p)C$.\n",
    "\n",
    "We first do Monte Carlo simulations to verify the asymptotic behavior of $\\widehat{B}$ and $\\tilde{\\beta}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tensor(1500): 100%|██████████| 10/10 [00:03<00:00,  3.07it/s]\n",
      "tensor(2250): 100%|██████████| 10/10 [00:04<00:00,  2.34it/s]\n",
      "tensor(3000): 100%|██████████| 10/10 [00:06<00:00,  1.60it/s]\n",
      "tensor(3750): 100%|██████████| 10/10 [00:09<00:00,  1.11it/s]\n",
      "tensor(4500): 100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n",
      "tensor(5250): 100%|██████████| 10/10 [00:16<00:00,  1.62s/it]\n",
      "tensor(6000): 100%|██████████| 10/10 [00:20<00:00,  2.01s/it]\n",
      "tensor(6750): 100%|██████████| 10/10 [00:50<00:00,  5.06s/it]\n",
      "tensor(7500): 100%|██████████| 10/10 [01:59<00:00, 11.96s/it]\n",
      "tensor(8250): 100%|██████████| 10/10 [01:59<00:00, 11.91s/it]\n",
      "tensor(9000): 100%|██████████| 10/10 [02:19<00:00, 13.94s/it]\n",
      "tensor(9750): 100%|██████████| 10/10 [02:10<00:00, 13.01s/it]\n",
      "tensor(10500): 100%|██████████| 10/10 [03:22<00:00, 20.22s/it]\n",
      "tensor(11250): 100%|██████████| 10/10 [03:50<00:00, 23.02s/it]\n",
      "tensor(12000): 100%|██████████| 10/10 [04:16<00:00, 25.65s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" no_oracle option is for the RGD stuff, which is still somewhat problematic. It shouldn't be turned on. \"\"\"\n",
    "N = 1000\n",
    "n_set = torch.arange(1500, 6001, 750)\n",
    "beta = [1,1,-4, 5]\n",
    "alpha_0 = [[10, 1, 1], [1, 10, 1], [1, 1, 10]]\n",
    "OL, OA, NO = True, True, True\n",
    "ntypes = OL + OA + NO\n",
    "\n",
    "oracle_guess_results = sim.ABC_Monte_Carlo.consistency_T2(number_of_iterations = N, \n",
    "                                          nodes_set = n_set,\n",
    "                                          beta = beta,\n",
    "                                          alpha_0 = alpha_0,\n",
    "                                          oracle_guess = True,\n",
    "                                          seeded = True,\n",
    "                                          constrained = False,\n",
    "                                          oracle_lat_pos = OL,\n",
    "                                          oracle_align = OA,\n",
    "                                          no_oracle = NO)\n",
    "shiwen_guess_results = sim.ABC_Monte_Carlo.consistency_T2(number_of_iterations = N, \n",
    "                                          nodes_set = n_set,\n",
    "                                          beta = beta,\n",
    "                                          alpha_0 = alpha_0,\n",
    "                                          oracle_guess = True,\n",
    "                                          seeded = True,\n",
    "                                          constrained = False,\n",
    "                                          oracle_lat_pos = OL,\n",
    "                                          oracle_align = OA,\n",
    "                                          no_oracle = NO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_guess_results.MC_result.est.to_csv(r\"simulated_data/theo_var_vs_emp_var/justify_oracle_guess/oracle_init_est.csv\")\n",
    "oracle_guess_results.MC_result.fish.to_csv(r\"simulated_data/theo_var_vs_emp_var/justify_oracle_guess/oracle_init_fish.csv\")\n",
    "\n",
    "shiwen_guess_results.MC_result.est.to_csv(r\"simulated_data/theo_var_vs_emp_var/justify_oracle_guess/lin_reg_init_est.csv\")\n",
    "shiwen_guess_results.MC_result.fish.to_csv(r\"simulated_data/theo_var_vs_emp_var/justify_oracle_guess/lin_reg_init_fish.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_init_fish = shiwen_guess_results.MC_result.fish\n",
    "methods = [\"method_1\", \"method_2\", \"method_3\"]\n",
    "id_vars = linreg_init_fish.columns.difference(methods)\n",
    "linreg_init_fish_longer = linreg_init_fish.melt(id_vars = id_vars, value_vars = methods, var_name = \"method\", value_name = \"value\")\n",
    "linreg_init_fish_longer = linreg_init_fish_longer[linreg_init_fish_longer[\"value\"] == 1]\n",
    "linreg_init_fish_longer.drop(columns = \"value\", inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" no_oracle option is for the RGD stuff, which is still somewhat problematic. It shouldn't be turned on. \"\"\"\n",
    "N = 1000\n",
    "n_set = torch.arange(1500, 12001, 750)\n",
    "beta = [1,1,-4, 5]\n",
    "alpha_0 = [[10, 1, 1], [1, 10, 1], [1, 1, 10]]\n",
    "OL, OA, NO = True, True, True\n",
    "ntypes = OL + OA + NO\n",
    "\n",
    "oracle_guess_results = sim.ABC_Monte_Carlo.consistency_T2(number_of_iterations = N, \n",
    "                                          nodes_set = n_set,\n",
    "                                          beta = beta,\n",
    "                                          alpha_0 = alpha_0,\n",
    "                                          oracle_guess = True,\n",
    "                                          seeded = True,\n",
    "                                          constrained = False,\n",
    "                                          oracle_lat_pos = OL,\n",
    "                                          oracle_align = OA,\n",
    "                                          no_oracle = NO)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00035075375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle_guess_results.MC_result.est[\"B_est\"] - shiwen_guess_results.MC_result.est[\"B_est\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.MC_result.est.to_csv(r\"simulated_data/emp_var_vs_obs_var/B_oracle.csv\")\n",
    "temp.MC_result.fish.to_csv(r\"simulated_data/emp_var_vs_obs_var/B_fish.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sim.ABC(time = 2,\n",
    "            nodes = 3,\n",
    "            beta = [1,1,-4, 5],\n",
    "            alpha_0 = [[10, 1, 1], [1, 10, 1], [1, 1, 10]])\n",
    "C = model.settings.C\n",
    "\n",
    "res = torch.tensor(temp.MC_result.est[\"B_est\"]).reshape(N*ntypes* len(n_set), 21).T\n",
    "\n",
    "\n",
    "df = pd.DataFrame(torch.linalg.solve(C.T @ C, C.T @ res).T)\n",
    "\n",
    "\n",
    "df.columns = [\"dim_\" + str(i) for i in range(4)]\n",
    "sns.histplot(df[\"dim_3\"])\n",
    "\n",
    "sns.scatterplot(data = temp.MC_result.est, x = \"nodes\", y = \"info_lost\")"
   ]
>>>>>>> Stashed changes
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
